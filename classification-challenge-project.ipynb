{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08803f57-2ac3-49f6-b09e-5aa3a4360bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf2a69e-8c9a-4b8a-9e2d-761da7195985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1.0/255., zoom_range=0.2, rotation_range=15,\n",
    "                                             width_shift_range=0.05, height_shift_range=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e0ce8f6-7469-4eeb-9c3a-27b9f256c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_TRAIN = \"./Covid19-dataset/train\"\n",
    "DIRECTORY_TEST = \"./Covid19-dataset/test\"\n",
    "CLASS_MODE = \"categorical\"\n",
    "COLOR_MODE = \"grayscale\"\n",
    "TARGET_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7644dc59-02c4-461c-827e-aa993fbedf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_iterator = data_generator.flow_from_directory(DIRECTORY_TRAIN, class_mode=CLASS_MODE, color_mode=COLOR_MODE, \n",
    "                                                               target_size=TARGET_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f4fef8f-cad2-4f24-8a5e-2c191acd2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch_input, sample_batch_labels = training_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaec8453-9098-4051-b142-cf1ac12a46c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 1) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sample_batch_input.shape, sample_batch_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f8f29df-888c-4944-a331-bc9d4c1ba3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_iterator = data_generator.flow_from_directory(DIRECTORY_TEST, class_mode=CLASS_MODE, color_mode=COLOR_MODE, \n",
    "                                                               target_size=TARGET_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "583f93c7-bf9a-47aa-874e-3ff8ed9980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch_input, sample_batch_labels = test_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb8831d2-f8ed-4808-a668-3ae6a6d807a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 1) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sample_batch_input.shape, sample_batch_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1badf5a1-a3fd-4f34-897a-4ead7210e929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sample_batch_input), type(sample_batch_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4bc948d-a841-42e8-a027-f2979e88d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_design(features):\n",
    "    model = Sequential(name=\"classification_model\")\n",
    "    model.add(Inputs(shape=(256, 256, 1)))\n",
    "    model.add(layers.Conv2D(2, 5, strides=3, padding=\"valid\", activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(5, 5), strides=(5, 5)))\n",
    "    model.add(layers.Conv2D(4, 3, strides=1, padding=\"valid\", activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "    opt = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss=losses.CategoricalCrossEntropy() , metrics=[metrics.CategoricalAccuracy(), metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b52ea-912c-4e45-a73b-9d0092e3aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml:Python",
   "language": "python",
   "name": "conda-env-python-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
